{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we combine the results of simulation but in a memory efficient way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path.\n",
    "folder_loc = '/vast/sr6364/perturbed_organics/data/adaptive_phase_diagram/delocalized'\n",
    "# folder_name = 'delocalized_goe_symmetric_N_100_s_100_mu_0.0_num_delta_200_num_input_200_num_trials_100_b0_1.0_b1_1.0_phase_diagram_log-scale'\n",
    "folder_name = 'delocalized_goe_symmetric_N_100_s_100_mu_0.0_num_delta_200_num_input_200_num_trials_100_b0_1.0_b1_1.0_phase_diagram_linear'\n",
    "path = os.path.join(folder_loc, folder_name)\n",
    "\n",
    "# Load parameters from JSON.\n",
    "param_file = os.path.join(path, \"parameters.json\")\n",
    "with open(param_file, \"r\") as f:\n",
    "    params = json.load(f)\n",
    "\n",
    "N = params[\"N\"]\n",
    "num_tasks = params[\"num_tasks\"]\n",
    "num_delta = params[\"num_delta\"]\n",
    "num_input = params[\"num_input\"]\n",
    "num_trials = params[\"num_trials\"]\n",
    "input_scale = params[\"input_scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/vast/sr6364/perturbed_organics/data/adaptive_phase_diagram/delocalized/delocalized_goe_symmetric_N_100_s_100_mu_0.0_num_delta_200_num_input_200_num_trials_100_b0_1.0_b1_1.0_phase_diagram_linear/spectral_radius_task_0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m var_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[43mcombine_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfill\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_tasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_tasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspec\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmask_source\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Now combine the \"condition\" variable.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m combine_variable(\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    127\u001b[0m     shape\u001b[38;5;241m=\u001b[39mvar_specs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     mask_source\u001b[38;5;241m=\u001b[39mvar_specs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcondition\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask_source\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    133\u001b[0m )\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mcombine_variable\u001b[0;34m(var_name, shape, fill_value, dtype, path, num_tasks, mask_source)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Load variable data and update only the valid indices.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     var_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvar_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_task_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     task_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     combined[indices] \u001b[38;5;241m=\u001b[39m task_data[indices]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# If this variable is not used as the mask, delete its task files.\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/ext3/miniconda3/envs/feed-r-conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/vast/sr6364/perturbed_organics/data/adaptive_phase_diagram/delocalized/delocalized_goe_symmetric_N_100_s_100_mu_0.0_num_delta_200_num_input_200_num_trials_100_b0_1.0_b1_1.0_phase_diagram_linear/spectral_radius_task_0.pt'"
     ]
    }
   ],
   "source": [
    "def combine_variable(var_name, shape, fill_value, dtype, path, num_tasks, mask_source=None):\n",
    "    \"\"\"\n",
    "    Combines task-specific files for a given variable into a single tensor.\n",
    "    \n",
    "    Parameters:\n",
    "      - var_name: Name of the variable to combine (e.g., \"spectral_radius\").\n",
    "      - shape: Full shape of the final combined tensor.\n",
    "      - fill_value: The fill value for positions not updated.\n",
    "      - dtype: Data type for the tensor.\n",
    "      - path: Directory containing the task files.\n",
    "      - num_tasks: Total number of task files.\n",
    "      - mask_source: If provided, the name of the task files to use as a mask.\n",
    "                     (For all variables here, we use the \"condition\" task files.)\n",
    "                     \n",
    "    The function loads for each task:\n",
    "      - The mask from \"<mask_source>_task_{i}.pt\" (if mask_source is given, otherwise uses var_name).\n",
    "      - The variable data from \"<var_name>_task_{i}.pt\".\n",
    "      \n",
    "    It uses the condition (mask != -1) to determine valid indices.\n",
    "    After combining, if the variable is not the mask source, its task files are deleted immediately.\n",
    "    (For \"condition\" we keep its task files until after the other variables are combined because they serve as the mask.)\n",
    "    \"\"\"\n",
    "    combined = torch.full(shape, fill_value=fill_value, dtype=dtype)\n",
    "    \n",
    "    for task_id in range(num_tasks):\n",
    "        # Use the mask from the mask_source if provided, otherwise use var_name.\n",
    "        mask_key = mask_source if mask_source is not None else var_name\n",
    "        mask_file = os.path.join(path, f\"{mask_key}_task_{task_id}.pt\")\n",
    "        mask_tensor = torch.load(mask_file)\n",
    "        indices = (mask_tensor != -1).nonzero(as_tuple=True)\n",
    "        \n",
    "        # Load variable data and update only the valid indices.\n",
    "        var_file = os.path.join(path, f\"{var_name}_task_{task_id}.pt\")\n",
    "        task_data = torch.load(var_file)\n",
    "        combined[indices] = task_data[indices]\n",
    "    \n",
    "    # If this variable is not used as the mask, delete its task files.\n",
    "    if mask_source is None or var_name != mask_source:\n",
    "        for task_id in range(num_tasks):\n",
    "            var_file = os.path.join(path, f\"{var_name}_task_{task_id}.pt\")\n",
    "            if os.path.exists(var_file):\n",
    "                os.remove(var_file)\n",
    "    \n",
    "    # Note: For \"condition\" we keep the int8 type without converting it to bool.\n",
    "    \n",
    "    # Save the combined tensor.\n",
    "    out_file = os.path.join(path, f\"{var_name}.pt\")\n",
    "    torch.save(combined, out_file)\n",
    "    print(f\"Combined and saved {var_name}.pt\")\n",
    "\n",
    "# Define the specifications for each variable.\n",
    "# Here we use the \"condition\" task files as the mask for all variables.\n",
    "var_specs = {\n",
    "    \"condition\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials),\n",
    "        \"fill\": -1,\n",
    "        \"dtype\": torch.int8,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"spectral_radius\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"norm_fixed_point_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"norm_fixed_point_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"actual_fixed_point_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"actual_fixed_point_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"first_order_perturb_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"first_order_perturb_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "    \"eigvals_J\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, 2 * N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.complex64,\n",
    "        \"mask_source\": \"condition\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# First, combine all variables except \"condition\" (which is used as the mask).\n",
    "for var_name, spec in var_specs.items():\n",
    "    if var_name == \"condition\":\n",
    "        continue\n",
    "    combine_variable(\n",
    "        var_name,\n",
    "        shape=spec[\"shape\"],\n",
    "        fill_value=spec[\"fill\"],\n",
    "        dtype=spec[\"dtype\"],\n",
    "        path=path,\n",
    "        num_tasks=num_tasks,\n",
    "        mask_source=spec[\"mask_source\"]\n",
    "    )\n",
    "\n",
    "# Now combine the \"condition\" variable.\n",
    "combine_variable(\n",
    "    \"condition\",\n",
    "    shape=var_specs[\"condition\"][\"shape\"],\n",
    "    fill_value=var_specs[\"condition\"][\"fill\"],\n",
    "    dtype=var_specs[\"condition\"][\"dtype\"],\n",
    "    path=path,\n",
    "    num_tasks=num_tasks,\n",
    "    mask_source=var_specs[\"condition\"][\"mask_source\"]\n",
    ")\n",
    "\n",
    "# Delete any remaining \"condition\" task files.\n",
    "for task_id in range(num_tasks):\n",
    "    mask_file = os.path.join(path, f\"condition_task_{task_id}.pt\")\n",
    "    if os.path.exists(mask_file):\n",
    "        os.remove(mask_file)\n",
    "\n",
    "print(\"Results saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to combbine old code \n",
    "\n",
    "def combine_variable(var_name, shape, fill_value, dtype, path, num_tasks, mask_source=None):\n",
    "    \"\"\"\n",
    "    Combines task-specific files for a given variable into a single tensor.\n",
    "    \n",
    "    Parameters:\n",
    "      - var_name: Name of the variable to combine (e.g., \"spectral_radius\").\n",
    "      - shape: Full shape of the final combined tensor.\n",
    "      - fill_value: The fill value for positions not updated.\n",
    "      - dtype: Data type for the tensor.\n",
    "      - path: Directory containing the task files.\n",
    "      - num_tasks: Total number of task files.\n",
    "      - mask_source: If provided, the name of the task files to use as a mask. \n",
    "                     (For all variables here, we use the bool_stable task files.)\n",
    "                     \n",
    "    The function loads for each task:\n",
    "      - The mask from \"<mask_source>_task_{i}.pt\" (if mask_source is given, otherwise uses var_name).\n",
    "      - The variable data from \"<var_name>_task_{i}.pt\".\n",
    "    It uses the condition (mask != -1) to determine valid indices.\n",
    "    \n",
    "    After combining, if var_name is not the same as mask_source, the task files for var_name\n",
    "    are deleted immediately. (For \"bool_stable\" we want to keep its task files until after the \n",
    "    other variables are combined because they serve as the mask.)\n",
    "    \"\"\"\n",
    "    combined = torch.full(shape, fill_value=fill_value, dtype=dtype)\n",
    "\n",
    "    # Loop over each task.\n",
    "    for task_id in range(num_tasks):\n",
    "        # Determine which task file to use for the mask.\n",
    "        # If mask_source is provided, use that; otherwise, use var_name.\n",
    "        mask_key = mask_source if mask_source is not None else var_name\n",
    "        mask_file = os.path.join(path, f\"{mask_key}_task_{task_id}.pt\")\n",
    "        mask_tensor = torch.load(mask_file)\n",
    "        indices = (mask_tensor != -1).nonzero(as_tuple=True)\n",
    "\n",
    "        # Load the variable-specific data.\n",
    "        var_file = os.path.join(path, f\"{var_name}_task_{task_id}.pt\")\n",
    "        task_data = torch.load(var_file)\n",
    "        combined[indices] = task_data[indices]\n",
    "\n",
    "    # If the variable is not the mask source, delete its task files immediately.\n",
    "    # (For bool_stable, we want to keep its task files for later use as a mask.)\n",
    "    if mask_source is None or var_name != mask_source:\n",
    "        for task_id in range(num_tasks):\n",
    "            var_file = os.path.join(path, f\"{var_name}_task_{task_id}.pt\")\n",
    "            if os.path.exists(var_file):\n",
    "                os.remove(var_file)\n",
    "    \n",
    "    # For bool_stable, convert the final result to a boolean tensor.\n",
    "    if var_name == \"bool_stable\":\n",
    "        combined = combined.bool()\n",
    "\n",
    "    # Save the combined tensor.\n",
    "    out_file = os.path.join(path, f\"{var_name}.pt\")\n",
    "    torch.save(combined, out_file)\n",
    "    print(f\"Combined and saved {var_name}.pt\")\n",
    "\n",
    "# Define the specifications for each variable.\n",
    "# Note: We use the bool_stable task files as the mask for all variables.\n",
    "var_specs = {\n",
    "    \"bool_stable\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials),\n",
    "        \"fill\": -1,\n",
    "        \"dtype\": torch.int8,\n",
    "        \"mask_source\": \"bool_stable\"  # For bool_stable, use its own task files (and postpone deletion).\n",
    "    },\n",
    "    \"spectral_radius\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"norm_fixed_point_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"norm_fixed_point_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"actual_fixed_point_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"actual_fixed_point_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"first_order_perturb_y\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"first_order_perturb_a\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.float16,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "    \"eigvals_J\": {\n",
    "        \"shape\": (num_delta, num_input, num_trials, 2 * N),\n",
    "        \"fill\": float(\"nan\"),\n",
    "        \"dtype\": torch.complex64,\n",
    "        \"mask_source\": \"bool_stable\"\n",
    "    },\n",
    "}\n",
    "\n",
    "# To ensure that the bool_stable task files are available for all other variables,\n",
    "# first combine all variables EXCEPT bool_stable.\n",
    "for var_name, spec in var_specs.items():\n",
    "    if var_name == \"bool_stable\":\n",
    "        continue\n",
    "    combine_variable(\n",
    "        var_name,\n",
    "        shape=spec[\"shape\"],\n",
    "        fill_value=spec[\"fill\"],\n",
    "        dtype=spec[\"dtype\"],\n",
    "        path=path,\n",
    "        num_tasks=num_tasks,\n",
    "        mask_source=spec[\"mask_source\"]\n",
    "    )\n",
    "\n",
    "# Now combine bool_stable. Its task files are used as the mask and are kept (i.e. not deleted)\n",
    "# inside combine_variable since var_name == mask_source.\n",
    "combine_variable(\n",
    "    \"bool_stable\",\n",
    "    shape=var_specs[\"bool_stable\"][\"shape\"],\n",
    "    fill_value=var_specs[\"bool_stable\"][\"fill\"],\n",
    "    dtype=var_specs[\"bool_stable\"][\"dtype\"],\n",
    "    path=path,\n",
    "    num_tasks=num_tasks,\n",
    "    mask_source=var_specs[\"bool_stable\"][\"mask_source\"]\n",
    ")\n",
    "\n",
    "# Finally, delete any remaining bool_stable task files.\n",
    "for task_id in range(num_tasks):\n",
    "    mask_file = os.path.join(path, f\"bool_stable_task_{task_id}.pt\")\n",
    "    if os.path.exists(mask_file):\n",
    "        os.remove(mask_file)\n",
    "\n",
    "# Optionally, compute and save percent_stable using the combined bool_stable.\n",
    "bool_stable = torch.load(os.path.join(path, \"bool_stable.pt\"))\n",
    "percent_stable = bool_stable.float().mean(dim=2) * 100\n",
    "torch.save(percent_stable, os.path.join(path, \"percent_stable.pt\"))\n",
    "print(\"Combined and saved percent_stable.pt\")\n",
    "\n",
    "print(\"Results saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feed-r-conda (Singularity)",
   "language": "python",
   "name": "feed-r-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
